# -*- coding: utf-8 -*-
"""ScamDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CBQYYkwHYHRByS9lvWRwWoi-PC99YBTM
"""

import os
import pandas as pd
import numpy as np
import seaborn as sns
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

os.listdir()
#load dataset
from google.colab import files
uploaded = files.upload()
df = pd.read_csv("Dataset_5971.csv")

#normalize column names
df.columns = [col.strip().lower() for col in df.columns]

#copy of dataset to clean
df_clean = df.copy()

#convert 'url' and 'phone' to binary, 0=no, 1=yes
df_clean['url']=df_clean['url'].apply(lambda x: 0 if str(x).strip().lower() == 'no' else 1)
df_clean['phone']=df_clean['phone'].apply(lambda x: 0 if str(x).strip().lower() == 'no' else 1)



#remove whitespace & convert 'label' column to lowercase, hot encode the labels
le = LabelEncoder()
df_clean['label']=df_clean['label'].astype(str).str.lower()
df_clean['label'] = le.fit_transform(df_clean['label'])
print(le.classes_)# 0=ham, 1=smishing, 2=spam

# remove 'email' column
df_clean.drop(columns=['email'], inplace=True)

# clean 'text' column by ensuring it contains strings and strip whitespace
df_clean['text'] = df_clean['text'].astype(str).str.strip()

#preview cleaned dataset
df_clean.head(100)

# Data Visualizations
plt.hist(df_clean['label'])
plt.show()

# vectorize the text

vectorizer = TfidfVectorizer()
vectorText = vectorizer.fit_transform(df_clean['text'])


# Combine TF-IDF features with the remaining features in dataset
X = np.hstack((vectorText.toarray(), df_clean[['url', 'phone']]))
y = df_clean['label']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

model1 = LogisticRegression()
model1.fit(X_train, y_train)
y_pred = model1.predict(X_test)
print(accuracy_score(y_test, y_pred))

# Confusion Matrix - Logistic Regression
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Logistic Regression")
plt.show()

# Classification Report - Logistic Regression
print("Classification Report - Logistic Regression")
print(classification_report(y_test, y_pred, target_names=le.classes_))

model2 = RandomForestClassifier()
model2.fit(X_train, y_train)
y_pred = model2.predict(X_test)
print(accuracy_score(y_test, y_pred))

# Confusion Matrix - Random Forest
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Random Forest")
plt.show()

# Classification Report - Random Forest
print("Classification Report - Random Forest")
print(classification_report(y_test, y_pred, target_names=le.classes_))

model3 = DecisionTreeClassifier()
model3.fit(X_train, y_train)
y_pred = model3.predict(X_test)
print(accuracy_score(y_test, y_pred))


# Confusion Matrix - Decision Tree
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Decision Tree")
plt.show()

# Classification Report - Decision Tree
print("Classification Report - Decision Tree")
print(classification_report(y_test, y_pred, target_names=le.classes_))

accuracies = [model1.score(X_test, y_test), model2.score(X_test, y_test), model3.score(X_test, y_test)]
model_names = ["Logistic Regression", "Random Forest", "Decision Tree"]
for i, acc in enumerate(accuracies):
    plt.text(i, acc + 0.005, f"{acc:.3f}", ha='center', fontsize=10)

plt.bar(model_names, accuracies, color=['#FFC0CB', '#90EE90', '#ADD8E6'])
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.ylim(0, 1)
plt.show()

texts = ["Amazon call us and txt prize contact claim is sending you a refunding of $32.64. Please reply with your bank account and routing number to receive your refund.",
         ]
newData = pd.DataFrame({
    'text': texts,
    'url': [0],
    'phone': [0]
})

vectorized = vectorizer.transform(newData['text'])
testVector = np.hstack((vectorized.toarray(), newData[['url', 'phone']]))


classNumber = model2.predict(testVector)

# classNumber is the encoded prediction(s), e.g., array([1, 0, 2])
original_labels = le.inverse_transform(classNumber)

for text, label in zip(texts, original_labels):
    print(f"Text: {text}\nPredicted label: {label}\n")

# Save the best model (Random Forest)
joblib.dump(model2, "model.pkl")

# Save the vectorizer
joblib.dump(vectorizer, "vectorizer.pkl")

# Save the label encoder
joblib.dump(le, "label_encoder.pkl")

Hey! Just wanted to check in and see how you're doing. Hope everything's going well ðŸ˜Š

Congratulations! Youâ€™ve won a $1,000 Walmart gift card! Claim here: wmartfreeprizze.net

Tired of slow WiFi? Switch to HyperNet today and get 2 months FREE! No contracts, no hassle. Call 1-800-FASTNET or visit hypernetnow.com